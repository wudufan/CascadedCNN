{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate the net prototxt file\n",
    "# easy to deduct what the functions are doing from the name, no need for documentation\n",
    "import caffe\n",
    "from caffe import layers as L, params as P\n",
    "import re\n",
    "import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AddConvModule(net, name, bottom=None, kernel_size=3, num_output=64,  \n",
    "                  pad = None, stride = 1, bnorm = True, ReLU = True, phase = caffe.TRAIN):\n",
    "    if pad is None:\n",
    "        pad = int(kernel_size / 2)\n",
    "    if bottom is None:\n",
    "        bottom = net.tops.keys()[-1]  #Use the last layer\n",
    "    \n",
    "    # Add convolution layer\n",
    "    net.tops['%s_conv' % name] = L.Convolution(\n",
    "        bottom=bottom, kernel_size=kernel_size, num_output=num_output, pad=pad, stride=stride,\n",
    "        weight_filler={'type':'xavier'},\n",
    "        bias_filler={'type':'constant', 'value':0}\n",
    "        )\n",
    "    \n",
    "    # Add bnorm layer\n",
    "    if bnorm is True:\n",
    "        net.tops['%s_conv_bnorm' % name] = L.BatchNorm(\n",
    "            bottom=net.tops.keys()[-1],\n",
    "            batch_norm_param={'use_global_stats':(phase==caffe.TEST)},\n",
    "            param={'lr_mult':0}, # remember to use regex to repeat this for two more times\n",
    "        )\n",
    "        net.tops['%s_conv_scale' % name] = L.Scale(\n",
    "            bottom=net.tops.keys()[-1],\n",
    "            scale_param={'bias_term':True}\n",
    "        )\n",
    "    \n",
    "    # Add ReLU layer\n",
    "    if ReLU is True:\n",
    "        net.tops['%s_conv_relu' % name] = L.ReLU(\n",
    "            bottom=net.tops.keys()[-1], \n",
    "        )\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateNetPrototxt(outputPath, dataPath, nConvModule, phase, dim0, dim2, nChannel=1, kernel_size=3):\n",
    "    ns = caffe.NetSpec()\n",
    "    \n",
    "    # data layers\n",
    "    if phase == caffe.TRAIN:\n",
    "        ns.data = L.Data(\n",
    "            type='HDF5Data',\n",
    "            input_param={'shape':{'dim':[1,nChannel+1,dim2,dim2]}},  \n",
    "            include={'phase':caffe.TRAIN}, \n",
    "            hdf5_data_param={'source':dataPath, 'batch_size': dim0})\n",
    "        ns.slice_data = L.Slice(\n",
    "            bottom='data', top=['dataSrc', 'dataRef'], # remember to remove the extra top\n",
    "            slice_param={'axis':1, 'slice_point':nChannel}, \n",
    "            include={'phase':caffe.TRAIN}) \n",
    "    else:\n",
    "        ns.data = L.Data(\n",
    "            type='Input',\n",
    "            input_param={'shape':{'dim':[dim0,nChannel,dim2,dim2]}},\n",
    "            top='dataSrc'\n",
    "            )\n",
    "\n",
    "    # conv layers\n",
    "    ns = AddConvModule(ns, '0', 'dataSrc', kernel_size, 64, bnorm = False, ReLU=True, phase = phase)\n",
    "    for i in range(1,nConvModule+1):\n",
    "        ns = AddConvModule(ns, '%d' %i, kernel_size=kernel_size, phase = phase)\n",
    "    ns = AddConvModule(ns, '%d' % (nConvModule+1), None, kernel_size, 1, bnorm = False, ReLU=False, phase = phase)\n",
    "\n",
    "    # loss layers\n",
    "    if phase == caffe.TRAIN:\n",
    "        ns.loss = L.EuclideanLoss(\n",
    "            bottom=[ns.tops.keys()[-1], 'dataRef'], \n",
    "            include={'phase':caffe.TRAIN})\n",
    "    \n",
    "    # post processing\n",
    "    sio = StringIO.StringIO()\n",
    "    print >> sio, ns.to_proto()\n",
    "    s = sio.getvalue()\n",
    "    if phase == caffe.TRAIN:\n",
    "        s2 = re.sub('( *)top:( *)\"slice_data\"\\n', '', s, re.DOTALL | re.M);\n",
    "    else:\n",
    "        s2 = re.sub('( *)top:( *)\"data\"\\n', '', s, re.DOTALL | re.M);\n",
    "\n",
    "    # find the param {lr_mult:0} and repeat it for another 2 times\n",
    "    searchPattern = '( *)param( *){\\n( *)lr_mult:( *)0\\n( *)}\\n'\n",
    "    m = re.search(searchPattern, s2)\n",
    "    if m is not None:\n",
    "        subString = m.group(0)\n",
    "        s3 = re.sub(searchPattern, subString+subString+subString, s2, re.DOTALL | re.M)\n",
    "    else:\n",
    "        s3 = s2\n",
    "    \n",
    "    # save file\n",
    "    with open(outputPath, 'w') as f:\n",
    "        f.write(s3)\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateADAMSolverPrototxt(outputPath, net, snapshot_prefix, \n",
    "                               max_iter=50000, snapshot=10000, display=10):\n",
    "    with open(outputPath, 'w') as f:\n",
    "        f.write('net: \"%s\"\\n'%net)\n",
    "        f.write('type: \"ADAM\"\\nbase_lr: 0.001\\nlr_policy: \"fixed\"\\ngamma: 1\\ndelta: 1e-8\\n')\n",
    "        f.write('momentum: 0.9\\nmomentum2: 0.999\\nweight_decay: 0.0001\\n')\n",
    "        f.write('max_iter: %d\\n'%max_iter)\n",
    "        f.write('display: %d\\n'%display)\n",
    "        f.write('snapshot: %d\\n'%snapshot)\n",
    "        f.write('snapshot_prefix: \"%s\"\\n'%snapshot_prefix)\n",
    "        f.write('solver_mode: GPU\\n')\n",
    "        f.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
